{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Predict picturebook lfw\n",
    "\n",
    "The model made in VGGFace clasification lfw is based on a subset of 17 classes of the dataset 'Faces in the wild'. This model is read from disk and used to predict a small number of pictures collected from the internet. The pictures contain at least one image of the faces that were trained, but in several cases additional unknown faces are there. First Opencv is used to detect faces on the pictures. Then the faces are classified using the model and the results are evaluated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "#from keras.preprocessing import image\n",
    "#from keras.applications.imagenet_utils import preprocess_input\n",
    "#from keras.layers import Dense, Activation, Flatten\n",
    "#from keras.layers import merge, Input\n",
    "#from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "#from sklearn.utils import shuffle\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "#from keras.preprocessing.image import load_img\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.models import model_from_json\n",
    "import cv2\n",
    "import glob\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the haarcascade classifier for face detection\n",
    "cascade_file_src = \"haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascade_file_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some command line arguments are needed to be able to execute the deep learning model for face detection\n",
    "args = {\n",
    "    \"prototxt\": \"deploy.prototxt.txt\",\n",
    "    \"model\": \"res10_300x300_ssd_iter_140000.caffemodel\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n"
     ]
    }
   ],
   "source": [
    "# load the serialized model from disk\n",
    "print(\"[INFO] loading model...\")\n",
    "net = cv2.dnn.readNetFromCaffe(args[\"prototxt\"], args[\"model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pictures and detect faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the combined haarcascade and deep learning function in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_faces3(image):\n",
    "    # First haarcascade is used to find faces \n",
    "    # Using low values of scaleFactor and minNeighbours (with many false positives)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.2, 3)\n",
    "    facecrop = []\n",
    "    # The faces are cropped and the resulting images are fed in a sequence to the neural net.\n",
    "    for f in faces:\n",
    "        x, y, w, h = [ v for v in f ]\n",
    "        facecrop.append(image[y:y+h, x:x+w])\n",
    "    confirmed = []\n",
    "    for img in facecrop:    \n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        # Probability function of 0.9 can be changed to filter false positives\n",
    "        if detections[0, 0, 0, 2] > 0.9:\n",
    "            face = cv2.resize(img,((224,224)))\n",
    "            confirmed.append(face)\n",
    "    print('# faces found:',len(confirmed))\n",
    "    return(confirmed)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testoutput2/\n",
      "Picturebook//Ann Veneman.jpg\n",
      "# faces found: 1\n",
      "Picturebook//Halle-Berry-Intro.jpg\n",
      "# faces found: 1\n",
      "Picturebook//howard_dean.jpg\n",
      "# faces found: 1\n",
      "Picturebook//lavrov.jpg\n",
      "# faces found: 2\n",
      "Picturebook//Nicole_kidman.jpg\n",
      "# faces found: 2\n",
      "Picturebook//Richard Gephard.jpg\n",
      "# faces found: 3\n",
      "Picturebook//salma-hayek-ashley-judd-golden-globes.jpg\n",
      "# faces found: 2\n",
      "Picturebook//Cheney and Trump.jpg\n",
      "# faces found: 1\n",
      "Picturebook//Jeb and George Bush.jpg\n",
      "# faces found: 2\n",
      "Picturebook//Harisson Ford.jpg\n",
      "# faces found: 2\n",
      "Picturebook//Naomi_Watts_Liev_Schreiber.jpg\n",
      "# faces found: 2\n",
      "Picturebook//Meryl_Streep.jpg\n",
      "# faces found: 1\n",
      "Picturebook//Britney Spears.jpg\n",
      "# faces found: 1\n",
      "Picturebook//nancy-pelosi-accompanied.jpg\n",
      "# faces found: 2\n",
      "Picturebook//Jennifer-Garner-Baby2Baby-Gala-Pictures-Copy1.jpg\n",
      "# faces found: 3\n",
      "testoutput2/.ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "# iterate over directories and files\n",
    "# detect faces using ext_faces\n",
    "# make a list of preprocessed images \n",
    "\n",
    "import os\n",
    "\n",
    "rootdir ='Picturebook/'\n",
    "n = len(rootdir)\n",
    "newdir=\"testoutput2\"\n",
    "img_data_list = []\n",
    "path_list =[]\n",
    "name_list = []\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    crdir = newdir + subdir[n-1:]\n",
    "    print(crdir)\n",
    "    os.makedirs(crdir)\n",
    "    for file in files:\n",
    "        if file[-4:] in (\".jpg\",\".JPG\"):\n",
    "            filepath = subdir + '/' + file\n",
    "            print(filepath)\n",
    "            image= cv2.imread(filepath)\n",
    "            name = file[:-4]\n",
    "            facecrop2 = ext_faces3(image)\n",
    "            for i, face in enumerate(facecrop2):\n",
    "                img_data_list.append(face)\n",
    "                name_list.append(name + '-' + format(i))\n",
    "                path_list.append(format(filepath))\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in the list above are the (maximum) sizes of the cropped faces detected. In almost every case these values are smaller then the input value of the model which is 224. The reason for this is these pictures are gathered from the internet and have a low resolution. The faces are resized to the right size (224x224) but as the complete resolution is not there in the original picture the classification might not use all features. In case of using your own picturebook this is less a problem as you probably have pictures with a higher resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Ann Veneman-0',\n",
       " 'Halle-Berry-Intro-0',\n",
       " 'howard_dean-0',\n",
       " 'lavrov-0',\n",
       " 'lavrov-1',\n",
       " 'Nicole_kidman-0',\n",
       " 'Nicole_kidman-1',\n",
       " 'Richard Gephard-0',\n",
       " 'Richard Gephard-1',\n",
       " 'Richard Gephard-2',\n",
       " 'salma-hayek-ashley-judd-golden-globes-0',\n",
       " 'salma-hayek-ashley-judd-golden-globes-1',\n",
       " 'Cheney and Trump-0',\n",
       " 'Jeb and George Bush-0',\n",
       " 'Jeb and George Bush-1',\n",
       " 'Harisson Ford-0',\n",
       " 'Harisson Ford-1',\n",
       " 'Naomi_Watts_Liev_Schreiber-0',\n",
       " 'Naomi_Watts_Liev_Schreiber-1',\n",
       " 'Meryl_Streep-0',\n",
       " 'Britney Spears-0',\n",
       " 'nancy-pelosi-accompanied-0',\n",
       " 'nancy-pelosi-accompanied-1',\n",
       " 'Jennifer-Garner-Baby2Baby-Gala-Pictures-Copy1-0',\n",
       " 'Jennifer-Garner-Baby2Baby-Gala-Pictures-Copy1-1',\n",
       " 'Jennifer-Garner-Baby2Baby-Gala-Pictures-Copy1-2']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(img_data_list),len(name_list))\n",
    "name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list above shows the names of the original pictures and the sequence of the number of faces collected from these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model_lfw.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_lfw.h5\")\n",
    "print(\"Loaded model from disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2_2 (Conv2D)             (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv3_3 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv4_2 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv4_3 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_1 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_2 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_3 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling2D)         (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc6/relu (Activation)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "fc7/relu (Activation)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc8 (Dense)                  (None, 2622)              10742334  \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 17)                44591     \n",
      "=================================================================\n",
      "Total params: 145,047,469\n",
      "Trainable params: 44,591\n",
      "Non-trainable params: 145,002,878\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# Make array of list\n",
    "img_data = np.array(img_data_list)\n",
    "print (img_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples = len(img_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 17)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a prediction on the trained model\n",
    "yhat = loaded_model.predict(img_data)\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of classes is loaded from file\n",
    "classes = np.loadtxt(\"classes.csv\",  dtype=str, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bill_Simon', 'Britney_Spears', 'Dick_Cheney', 'Halle_Berry',\n",
       "       'Harrison_Ford', 'Howard_Dean', 'Jeb_Bush', 'Jennifer_Garner',\n",
       "       'John_Snow', 'Meryl_Streep', 'Nancy_Pelosi', 'Naomi_Watts',\n",
       "       'Nicole_Kidman', 'Richard_Gephardt', 'Salma_Hayek', 'Sergey_Lavrov',\n",
       "       'Ann_Veneman'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The labels are assigned. By using a threshold (unknown_prob) pictures with a lower maximum probability can be assigned to a \n",
    "# separate category. This threshold is arbitrary and leads to false positives and false negatives.\n",
    "unknown_prob = 0.5\n",
    "results = []\n",
    "for pred in yhat:\n",
    "    if np.max(pred[::-1]) > unknown_prob:\n",
    "        top_indices = pred.argsort()[-1:][::-1]\n",
    "        result = [[str(classes[i]), pred[i]] for i in top_indices]\n",
    "        result.sort(key=lambda x: x[1], reverse=True)\n",
    "        results.append(result[0][0])\n",
    "    else: results.append('unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "In most cases the subject of the picture is classified right. But the other unknown faces on the pictures in various cases are incorrectly assigned to labels while they should be 'unknown'. The probability of these faces is too high for the threshold. Increasing the threshold might help but can decrease the number of right classified faces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ann Veneman-0 Ann_Veneman\n",
      "Halle-Berry-Intro-0 Halle_Berry\n",
      "howard_dean-0 Howard_Dean\n",
      "lavrov-0 John_Snow\n",
      "lavrov-1 unknown\n",
      "Nicole_kidman-0 Britney_Spears\n",
      "Nicole_kidman-1 Nicole_Kidman\n",
      "Richard Gephard-0 Richard_Gephardt\n",
      "Richard Gephard-1 unknown\n",
      "Richard Gephard-2 Bill_Simon\n",
      "salma-hayek-ashley-judd-golden-globes-0 Nicole_Kidman\n",
      "salma-hayek-ashley-judd-golden-globes-1 Salma_Hayek\n",
      "Cheney and Trump-0 Dick_Cheney\n",
      "Jeb and George Bush-0 Sergey_Lavrov\n",
      "Jeb and George Bush-1 Jeb_Bush\n",
      "Harisson Ford-0 Harrison_Ford\n",
      "Harisson Ford-1 Nicole_Kidman\n",
      "Naomi_Watts_Liev_Schreiber-0 Naomi_Watts\n",
      "Naomi_Watts_Liev_Schreiber-1 Howard_Dean\n",
      "Meryl_Streep-0 Meryl_Streep\n",
      "Britney Spears-0 Britney_Spears\n",
      "nancy-pelosi-accompanied-0 Nancy_Pelosi\n",
      "nancy-pelosi-accompanied-1 unknown\n",
      "Jennifer-Garner-Baby2Baby-Gala-Pictures-Copy1-0 Jennifer_Garner\n",
      "Jennifer-Garner-Baby2Baby-Gala-Pictures-Copy1-1 Naomi_Watts\n",
      "Jennifer-Garner-Baby2Baby-Gala-Pictures-Copy1-2 unknown\n"
     ]
    }
   ],
   "source": [
    "len(results)\n",
    "len(name_list)\n",
    "for i, x in enumerate(results):\n",
    "    print(name_list[i],results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an overview of the top 5 probabilities per picture\n",
    "top=5\n",
    "ereval = []\n",
    "for pred in yhat:\n",
    "    top_indices = pred.argsort()[-top:][::-1]\n",
    "    erev = [[str(classes[i]), pred[i]] for i in top_indices]\n",
    "    erev.sort(key=lambda x: x[1], reverse=True)\n",
    "    ereval.append(erev)\n",
    "# ereval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you want to inspect the faces captured from the pictures you can write them to folders below. These pictures can be used to be added  to the trainingset and retrain the model, with additional labels if you want. In the end the classification result can be used to generate a file of classified faces per picture that can be stored and used to search for faces in a collection of photographs/snapshots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, face in enumerate(img_data):\n",
    "    if results[i] == 'unknown':\n",
    "        cv2.imwrite(\"unknown/\" + name_list[i] + \"_\" + str(i) + \".jpg\", face)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
